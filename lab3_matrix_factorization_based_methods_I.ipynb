{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3 matrix factorization based methods I.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoNl11xqCa2jsfMG+rPjCY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkbu-kennycheng/comp7240/blob/main/lab3_matrix_factorization_based_methods_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5tCVmgyTBuZ"
      },
      "source": [
        "# Lab 3: matrix factorization based methods I\n",
        "\n",
        "In this lab, we would do experiment on Singular Value Decomposition (SVD) and Probabilistic Matrix Factorization (PMF) algorthium. Let's start with installing `surprise` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTQbwGI6Xgc5",
        "outputId": "b555e1a8-8721-42b5-bc3e-4b51f02dc846"
      },
      "source": [
        "!pip install surprise"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: surprise in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.7/dist-packages (from surprise) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flRxb3zaxxdQ"
      },
      "source": [
        "# Dataset: [Amazon Review Data](https://nijianmo.github.io/amazon/index.html)\n",
        "\n",
        "Let's take a look to today's dataset.\n",
        "\n",
        "![](https://url2img-web.herokuapp.com/aHR0cHM6Ly9uaWppYW5tby5naXRodWIuaW8vYW1hem9uL2luZGV4Lmh0bWwjbWFpbg==)\n",
        "\n",
        "Although the whole dataset is quite big. There is a sample dataset with only Home and Kitchen product reviews in json format. Let's download it by `curl` command and unzip it with `zcat`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9H5Nkz7x1Ke",
        "outputId": "70e4570d-cda5-44f7-e4ef-b6c748be5396"
      },
      "source": [
        "!curl http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Digital_Music_5.json.gz | zcat > data.json"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 18.5M  100 18.5M    0     0  15.8M      0  0:00:01  0:00:01 --:--:-- 15.8M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3VoYOY3Oooa"
      },
      "source": [
        "We could use `json` library to load the json file into a list by taking out only `reviewerID`, `asin` and `overall`.\n",
        "- `reviewerID` is the user ID in string format.\n",
        "- `asin` is an unique identifier of a particular product.\n",
        "- `overall` is the rating for the product given by the user. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9C2HPFAyW5W"
      },
      "source": [
        "import json\n",
        "\n",
        "# reviews = pd.DataFrame(columns=['reviewerID', 'asin', 'overall'])\n",
        "reviews = []\n",
        "with open('data.json', 'r') as f:\n",
        "    for l in f:\n",
        "        r = json.loads(l)\n",
        "        reviews.append([r['reviewerID'], r['asin'], r['overall']])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgF6tUIZIOYD",
        "outputId": "8379a83a-692e-4594-8a69-aeb42d367942"
      },
      "source": [
        "reviews[0]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A2TYZ821XXK2YZ', '3426958910', 5.0]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz2NrFr4PW3e"
      },
      "source": [
        "Since `reviewerID` and `asin` is in string format, changing to numeric value is needed before passing in to algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB7i4Xebyt5q"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(reviews)\n",
        "\n",
        "# build a dictionary of reviewerID to numeric ID by index\n",
        "reviewerIDs = df[0].unique()\n",
        "reviewerIDdict = dict(zip(reviewerIDs, range(len(reviewerIDs))))\n",
        "\n",
        "# build a dictionary of asin to numeric ID by index\n",
        "asins = df[1].unique()\n",
        "asinDict = dict(zip(asins, range(len(asins))))\n",
        "\n",
        "# replace reviewerID and asin to numeric value by the dictionaries\n",
        "df[0] = df[0].replace(reviewerIDdict)\n",
        "df[1] = df[1].replace(asinDict)\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzPyx-qJPsIi"
      },
      "source": [
        "After converting to numerice value, we could wrap it as `Dataset` using `load_from_df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GmFzuMa0juR"
      },
      "source": [
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "\n",
        "# build the reader object by specifying rating scale\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# load the data with from panda data frame\n",
        "data = Dataset.load_from_df(df, reader=reader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3DPrbdMP--y"
      },
      "source": [
        "Finally, split it in training set and testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7fbCXzGP9t9"
      },
      "source": [
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# sample random trainset and testset\n",
        "# test set is made of 25% of the ratings.\n",
        "trainset, testset = train_test_split(data, test_size=.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJQdA25XXWGt"
      },
      "source": [
        "## Singular Value Decomposition (SVD)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t94mEA2VXY2v"
      },
      "source": [
        "from surprise import SVD\n",
        "from surprise import accuracy\n",
        "\n",
        "# We'll use the famous SVD algorithm.\n",
        "algo = SVD()\n",
        "\n",
        "# Train the algorithm on the trainset, and predict ratings for the testset\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Then compute RMSE\n",
        "accuracy.rmse(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8SIHAZJkqOK"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReBTAiMQkp4l"
      },
      "source": [
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# Run 5-fold cross-validation and print results\n",
        "cross_validate(algo, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMIGBL8fK1-x"
      },
      "source": [
        "# Probabilistic Matrix Factorization (PMF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcm7zS02K3mJ"
      },
      "source": [
        "# By setting biased to False, it is equivalent to PMF.\n",
        "algo = SVD(biased=False)\n",
        "\n",
        "# Train the algorithm on the trainset, and predict ratings for the testset\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Then compute RMSE\n",
        "accuracy.rmse(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQoYMrDmkvdt"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExV4SVVrkw3E"
      },
      "source": [
        "# Run 5-fold cross-validation and print results\n",
        "cross_validate(algo, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}