{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab2: content-based methods.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZlVpPR3vNxC5ECcoMLG96",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkbu-kennycheng/comp7240/blob/main/lab2_content_based_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZT7LiDpAYOp"
      },
      "source": [
        "# Lab 2: content-based methods\n",
        "\n",
        "We are going to cover another two CF techniques in this lab, baseline method and factorization machine (FM). With another dataset for this lab, it also demonstrate how to import data from csv file in `surprise`.\n",
        "\n",
        "Let's install `surprise` with `pip` command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niQuWRoFAV7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa51ed1c-fb20-4458-8ca3-a17126c9b77a"
      },
      "source": [
        "!pip install surprise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1619442 sha256=9e033614a99276e3b3d31eba87a12bec996373392c9842f6c77bcee8f6d4a80b\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJQdA25XXWGt"
      },
      "source": [
        "# Dataset: CiaoDVD\n",
        "\n",
        "![](https://url2img-web.herokuapp.com/aHR0cHM6Ly9ndW9ndWliaW5nLmdpdGh1Yi5pby9saWJyZWMvZGF0YXNldHMuaHRtbCNjaWFvZHZk)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJfBD-yCChqI",
        "outputId": "1f0f0e45-ea4b-414c-ee50-d939b095e85d"
      },
      "source": [
        "!curl https://guoguibing.github.io/librec/datasets/CiaoDVD.zip > CiaoDVD.zip\n",
        "!unzip CiaoDVD.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 5678k  100 5678k    0     0  21.6M      0 --:--:-- --:--:-- --:--:-- 21.5M\n",
            "Archive:  CiaoDVD.zip\n",
            "  inflating: movie-ratings.txt       \n",
            "  inflating: readme.txt              \n",
            "  inflating: review-ratings.txt      \n",
            "  inflating: trusts.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-AGhNZHNJAf",
        "outputId": "ef76349a-4cf8-4576-b3d1-ff842ccb1c95"
      },
      "source": [
        "!head -n 20 readme.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Collection Duration: 2013-11 --- 2013-12\r\n",
            "Author: Guibing Guo\r\n",
            "\r\n",
            "========================================= Collected Data Formats ==================================\r\n",
            "Dataset Name: CiaoDVDs\r\n",
            "\r\n",
            "1. Ciao movie ratings format:  \r\n",
            "    1) File: movie-ratings.txt (size: 72,665 --> 72.7K)\r\n",
            "    2) Columns: userID, movieID, genreID, reviewID, movieRating, date\r\n",
            "\r\n",
            "2. Ciao review ratings format: \r\n",
            "    1) File: review-ratings.txt (size: 1,625,480 --> 1.6M)\r\n",
            "    2) Columns: userID, reviewID, reviewRating\r\n",
            "    3) Note: There are users who do not provide movie ratings but provide review ratings.\r\n",
            "    \r\n",
            "3. Ciao user trusts fromat:\r\n",
            "    1) File: trusts.txt (size: 40,133 --> 40K)\r\n",
            "    2) Columns: trustorID, trusteeID, trustValue\r\n",
            "    3) Note: There are users who may not provide neither movie rating nor review ratings. \r\n",
            "\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkWFNz_LNDOa",
        "outputId": "4194261f-01dd-46a3-daa1-56c6f248abc3"
      },
      "source": [
        "!head review-ratings.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4064,21,3\n",
            "931,27,4\n",
            "1869,41,3\n",
            "44,17,3\n",
            "9370,26,4\n",
            "2355,33,3\n",
            "17616,40,4\n",
            "17198,29,2\n",
            "7802,35,4\n",
            "6567,19,3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRts7sZopQkt"
      },
      "source": [
        "## Import data from csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la8Xj98naiwj"
      },
      "source": [
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "\n",
        "# path to dataset file\n",
        "file_path = 'review-ratings.txt'\n",
        "\n",
        "# seperate user item rating using comma\n",
        "reader = Reader(sep=',')\n",
        "\n",
        "data = Dataset.load_from_file(file_path, reader=reader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzRRvnuX4RYO"
      },
      "source": [
        "## Split training set and testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di1bEpGN-aWK"
      },
      "source": [
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# sample random trainset and testset\n",
        "# test set is made of 25% of the ratings.\n",
        "trainset, testset = train_test_split(data, test_size=.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWlSRf_BOJYI"
      },
      "source": [
        "# Baseline method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cclpgeBPMAFP",
        "outputId": "5eda3c18-2e5b-43bc-d65b-49aa56affa8e"
      },
      "source": [
        "from surprise import BaselineOnly\n",
        "from surprise import accuracy\n",
        "\n",
        "algo = BaselineOnly()\n",
        "\n",
        "# Train the algorithm on the trainset, and predict ratings for the testset\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Then compute RMSE\n",
        "accuracy.rmse(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "RMSE: 0.4371\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43710140568986233"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWsa-LOb-QoM"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1GH35ie4_-F",
        "outputId": "56463f51-65eb-474d-9b22-c6475ec188e2"
      },
      "source": [
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# We can now use this dataset as we please, e.g. calling cross_validate\n",
        "cross_validate(algo, data, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.4334  0.4355  0.4345  0.4333  0.4347  0.4343  0.0008  \n",
            "MAE (testset)     0.2850  0.2858  0.2853  0.2850  0.2860  0.2854  0.0004  \n",
            "Fit time          11.07   11.93   11.66   11.94   11.79   11.68   0.32    \n",
            "Test time         3.13    3.06    3.07    3.05    3.91    3.24    0.33    \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (11.069742679595947,\n",
              "  11.931014060974121,\n",
              "  11.65737795829773,\n",
              "  11.937498092651367,\n",
              "  11.786023378372192),\n",
              " 'test_mae': array([0.28504849, 0.28581043, 0.28533574, 0.28500527, 0.2860029 ]),\n",
              " 'test_rmse': array([0.43340316, 0.43547669, 0.43452349, 0.43328752, 0.43469859]),\n",
              " 'test_time': (3.1336288452148438,\n",
              "  3.061807632446289,\n",
              "  3.067690849304199,\n",
              "  3.0496153831481934,\n",
              "  3.9117496013641357)}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU45Fvxeu1y4"
      },
      "source": [
        "# Factorization Machines (FM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzbE_ObGu4Ze"
      },
      "source": [
        "from surprise import AlgoBase\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import cross_validate\n",
        "import numpy as np\n",
        "\n",
        "class MyOwnFM(AlgoBase):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        # Always call base method before doing anything.\n",
        "        AlgoBase.__init__(self)\n",
        "\n",
        "    def estimate(self, u, i):\n",
        "        \n",
        "        return 3\n",
        "\n",
        "\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "algo = MyOwnFM()\n",
        "\n",
        "cross_validate(algo, data, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}